{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import unicodedata\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "FOLDER_NAME = \"TrainingSet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "for path, dirs, files in os.walk(f\"./{FOLDER_NAME}\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            f = open(os.path.join(path, file), encoding=\"utf-8-sig\")\n",
    "            json_data.append(json.load(f))\n",
    "            json_data[-1][\"FileName\"] = file\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_CONVERSION = {\n",
    "    9:32,           # \\t -> \\s\n",
    "    10:32,          # \\n -> \\s\n",
    "    33:32,          # ! -> \\s\n",
    "    35:32,\n",
    "    38:32,          # & -> \\s\n",
    "    40:32,          # ( -> \\s\n",
    "    41:32,          # ) -> \\s\n",
    "    42:32,\n",
    "    43:32,          # + -> \\s\n",
    "    47:45,          # / -> -\n",
    "    58:32,          # : -> \\s\n",
    "    59:32,          # ; -> \\s           \n",
    "    60:-1,          # < ->\n",
    "    61:32,          # = -> \\s\n",
    "    62:-1,          # > -> \n",
    "    63:32,          # ? -> \\s\n",
    "    64:32,\n",
    "    91:-1,          # [ ->\n",
    "    93:-1,          # ] ->\n",
    "    94:39,          # ^ -> '\n",
    "    95:45,          # _ -> -\n",
    "    96:39,\n",
    "    123:-1,\n",
    "    124:32,         # | -> \\s\n",
    "    125:-1,         # } -> \n",
    "    160:32,         #  -> \\s\n",
    "    167:32,         # § -> \\s\n",
    "    170:-1,         # ª -> \n",
    "    171:32,         # « -> \\s\n",
    "    176:-1,         # ° ->\n",
    "    180:39,\n",
    "    182:-1,         # ¶ ->     \n",
    "    184:-1,         # ¸ ->\n",
    "    187:32,         # » -> \\s\n",
    "    223:-1,         # ß ->\n",
    "    224:97,         # à -> a\n",
    "    225:97,         # á -> a\n",
    "    226:97,         # â -> a\n",
    "    228:97,         # ä -> a\n",
    "    229:97,         # å -> a\n",
    "    230:101,        # æ -> e\n",
    "    232:101,        # è -> e\n",
    "    233:101,        # é -> e\n",
    "    234:101,        # ê -> e\n",
    "    235:101,        # ë -> e\n",
    "    236:105,        # ì -> i\n",
    "    237:105,        # í -> i\n",
    "    238:105,        # î -> i\n",
    "    239:105,        # ï -> i\n",
    "    241:110,\n",
    "    242:111,        # ò -> o\n",
    "    243:111,        # ó -> o\n",
    "    244:111,        # ô -> o\n",
    "    245:111,\n",
    "    248:111,        # ø -> o\n",
    "    249:117,        # ù -> u\n",
    "    250:117,\n",
    "    251:117,        # û -> u\n",
    "    257:97,         # ā -> a\n",
    "    261:97,         # ą -> a\n",
    "    263:99,         # ć -> c\n",
    "    269:99,         # č -> c\n",
    "    279:101,        # ė -> e\n",
    "    299:105,        # ī -> i\n",
    "    322:108,\n",
    "    324:110,\n",
    "    353:115,        # š -> s\n",
    "    363:117,        # ū -> u\n",
    "    369:252,\n",
    "    382:122,        # ž -> z\n",
    "    523:105,        # ȋ -> i\n",
    "    537:351,\n",
    "    601:101,        # ə -> e\n",
    "    699:39,         # ʻ -> '\n",
    "    700:39,         # ʼ -> '\n",
    "    703:39,         # ʿ -> '\n",
    "    706:-1,         # ˂ ->\n",
    "    714:39,         # ˊ -> '\n",
    "    727:-1,         # ˗ ->\n",
    "    774:{103: 287}, # g + Ux774 -> ğ\n",
    "    775:{105: 105}, # i + Ux307 -> i\n",
    "    8201:32,        #  -> \\s \n",
    "    8208:45,        # ‐ -> -\n",
    "    8211:45,        # – -> -\n",
    "    8212:45,        # — -> -\n",
    "    8216:39,        # ‘ -> '\n",
    "    8217:39,        # ’ -> '\n",
    "    8220:-1,        # “ -> \n",
    "    8221:-1,        # ” ->\n",
    "    8232:32,        #  -> \\s\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_CONVERSION = {\n",
    "    \"$\": \"dolar\",\n",
    "    \"…\": \" \",\n",
    "    \"ﬀ\": \"ff\",\n",
    "    \"ﬁ\": \"fi\",\n",
    "    \"ﬂ \": \"fl\",\n",
    "    \"ﬂ\": \"fl\",\n",
    "    \"ﬄ\": \"ffl\",\n",
    "    \"n°\": \"no \",\n",
    "    \"N°\": \"no \",\n",
    "    \"Anahtar Kelimeler:\": \"\",\n",
    "    \"I\": \"ı\",\n",
    "    \"İ\": \"i\",\n",
    "    \"SMK\": \"sınai mülkiyet kanunu\",\n",
    "    \"VII.\": \"7.\",\n",
    "    \"⅔\": \"%67\",\n",
    "    \"⅕\": \"%20\",\n",
    "    \"⅘\": \"%80\",\n",
    "    \"⅚\": \"%83\",\n",
    "    \"¼\": \"%25\",\n",
    "    \"½\": \"%50\",\n",
    "    \"¾\": \"%75\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEX_CONVERSION = {\n",
    "    r\"cov[ı,i]d-*\\s*19\": \"covid-19\",\n",
    "    r\"t?mk[\\s\\.]\": \"türk medeni kanunu \",\n",
    "    r\"(m\\.?\\s?)((\\d)+)\": r\"madde \\2\",\n",
    "    r\"<([a-z]+)(?![^>]*\\/>)[^>]*>\": \"\",\n",
    "    r\"\\.\": \" \",\n",
    "    r\"-\": \" \",\n",
    "    r\"'\": \"\",\n",
    "    r\"%\": \" yüzde \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    for key in STRING_CONVERSION.keys():\n",
    "        string = string.replace(key, STRING_CONVERSION[key])\n",
    "    string = string.lower()\n",
    "    result = []\n",
    "    for char in string:\n",
    "        if unicodedata.combining(char):\n",
    "            try:\n",
    "                result[-1] = chr(CHAR_CONVERSION[ord(char)][ord(result[-1])])\n",
    "            except:\n",
    "                continue\n",
    "        elif ord(char) in CHAR_CONVERSION.keys():\n",
    "            if CHAR_CONVERSION[ord(char)] != -1:\n",
    "                result.append(chr(CHAR_CONVERSION[ord(char)]))\n",
    "        elif ord(char) >= 942:      # greek and cyrillic alphabet\n",
    "            continue\n",
    "        else:\n",
    "            result.append(char)\n",
    "    result_str = ''.join(result)\n",
    "    result_str = ' '.join([w for w in result_str.split(\" \") if w != \"\"])\n",
    "    while result_str.startswith(\".\") or result_str.startswith(\"'\") or result_str.startswith(\"&\") or result_str.startswith(\"-\"):\n",
    "        result_str = result_str[1:]\n",
    "    while result_str.endswith(\".\") or result_str.endswith(\"'\") or result_str.endswith(\"&\") or result_str.endswith(\"-\"):\n",
    "        result_str = result_str[0:-1]\n",
    "    for key in REGEX_CONVERSION.keys():\n",
    "        result_str = re.sub(key, REGEX_CONVERSION[key], result_str)\n",
    "    return((result_str).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(li):\n",
    "    clean_list = []\n",
    "    for item in li:\n",
    "        if len(item.split(\",\")) > 1:\n",
    "            clean_list.extend([it for it in item.split(\",\") if it != \"\"])\n",
    "        elif len(item.split(\";\")) > 1:\n",
    "            clean_list.extend([it for it in item.split(\";\") if it != \"\"])\n",
    "        else:\n",
    "            clean_list.append(item)\n",
    "    clean_list = [clean_text(text) for text in clean_list]\n",
    "    # clean_list = list(dict.fromkeys(clean_list))\n",
    "    clean_list = ' '.join(clean_list)\n",
    "    return [text for text in clean_list.split(\" \") if text != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_chars_and_words(list_flat):\n",
    "    list_unique = []\n",
    "    list_dict = {}\n",
    "    list_chars = []\n",
    "    list_charcodes = []\n",
    "    for w in list_flat:\n",
    "        if w[0] not in list_unique:\n",
    "            list_unique.append(w[0])\n",
    "            list_dict[w[0]] = [w[1]]\n",
    "        else:\n",
    "            list_dict[w[0]].append(w[1])\n",
    "        for c in w[0]:\n",
    "            if c not in list_chars:\n",
    "                list_chars.append(c)\n",
    "                list_charcodes.append((ord(c), w[0]))\n",
    "    list_chars = [[list_chars[i], list_charcodes[i][0], list_charcodes[i][1]] for i, c in enumerate(list_chars)]\n",
    "    list_unique = [[list_unique[i], len(list_dict[list_unique[i]]), list_dict[list_unique[i]]] for i,_ in enumerate(list_unique)]\n",
    "    return (list_chars, list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing of input matrix, with removing emails, urls and html codes\n",
    "\n",
    "for data_obj in json_data:\n",
    "    data_obj[\"Metin\"] = re.sub(r\"[-\\w\\.]+@([-\\w]+\\.)+[-\\w]{2,4}\", \"\", data_obj[\"Metin\"])\n",
    "    data_obj[\"Metin\"] = re.sub(r\"https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*)\", \"\", data_obj[\"Metin\"])\n",
    "    data_obj[\"Metin\"] = re.sub(r\"<([a-z]+)(?![^>]*\\/>)[^>]*>\", \"\", data_obj[\"Metin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [(data_obj[\"FileName\"], clean_list(data_obj[\"Metin\"].split(\" \"))) for data_obj in json_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [(w[0], len(w[1]), w[1]) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_flat = [(w, wvec[0]) for wvec in words for w in wvec[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique = []\n",
    "for i, w in enumerate(w_flat):\n",
    "    if i%10000 == 0:\n",
    "        print(i)\n",
    "    if w[0] not in words_unique:\n",
    "        words_unique.append(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w_chars, w_unique = unique_chars_and_words(w_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique = []\n",
    "list_dict = {}\n",
    "for w in w_flat:\n",
    "    if w[0] not in words_unique:\n",
    "        words_unique.append(w[0])\n",
    "        list_dict[w[0]] = [w[1]]\n",
    "    else:\n",
    "        list_dict[w[0]].append(w[1])\n",
    "words_unique = [[words_unique[i], len(list_dict[words_unique[i]]), list_dict[words_unique[i]]] for i,_ in enumerate(words_unique)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [(data_obj[\"FileName\"], clean_list(data_obj[\"Anahtar Kelimeler\"])) for data_obj in json_data]\n",
    "kw_flat = [(kw, kwvec[0]) for kwvec in keywords for kw in kwvec[1]]\n",
    "kw_chars, kw_unique = unique_chars_and_words(kw_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unmatched_kw = []\n",
    "for kw in kw_unique:\n",
    "    s = ' '.join([w[0] for w in w_unique])\n",
    "    for kww in kw[0].split(\" \"):\n",
    "        if kww not in s:\n",
    "            unmatched_kw.append((kww, kw[0]))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words1 = [(data_obj[\"FileName\"], clean_list(data_obj[\"Metin\"].split(\" \"))) for data_obj in json_data if data_obj[\"FileName\"]==\"Hacettepe Üniversitesi 20.pdf.json\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
